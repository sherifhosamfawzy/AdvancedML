{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NeuralMachineTranslation_Bidrectional.ipynb","provenance":[{"file_id":"1C_Vo0iYKCbxnWVp88aSjeMB5csnFUhFl","timestamp":1586427516069}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Ru_75jFMriCY","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torchtext.datasets import TranslationDataset\n","from torchtext.data import Field, Iterator\n","import spacy\n","import numpy as np\n","import random\n","import math\n","import time\n","from collections import defaultdict\n","from matplotlib import pyplot as plt\n","from nltk.translate.bleu_score import sentence_bleu\n","from google.colab import drive"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VtLmhlcG6eNT","colab_type":"code","colab":{}},"source":["# Set the seed so that results are reproducible\n","SEED = 1234\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7ci6Mt8FjMQv","colab_type":"code","outputId":"77b1460a-a920-49fc-a581-5925d8d0406f","executionInfo":{"status":"ok","timestamp":1586599305715,"user_tz":-330,"elapsed":42060,"user":{"displayName":"Abhinav Havaldar","photoUrl":"","userId":"17469083248397030696"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["# Mount Google Drive to access data sets\n","drive.mount('/content/gdrive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YRO9qKWil17u","colab_type":"code","colab":{}},"source":["# Define Tokens\n","sos_token='<sos>'\n","eos_token='<eos>'\n","pad_token='<pad>'\n","unk_token='<unk>'\n","\n","# Tokenization function\n","def tokenize(text):\n","    return text.split()\n","\n","# Create Fields for both source and target languages\n","# using the tokenization function defined and lowercasing the text   \n","sourceLanguage = targetLanguage = Field(sequential = True, \n","                                        use_vocab = True, \n","                                        init_token = sos_token, \n","                                        eos_token = eos_token, \n","                                        fix_length = None, \n","                                        dtype = torch.long, \n","                                        lower = True,\n","                                        tokenize = tokenize,\n","                                        pad_token = pad_token, \n","                                        unk_token = unk_token)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8B91mtxdmVcL","colab_type":"code","colab":{}},"source":["# Load data from Google Drive, use only training data with maximum lenght of 50\n","train_data = TranslationDataset(\"/content/gdrive/My Drive/data/europarl-v7.fr-en\", \n","                             exts=('.en', '.fr'), \n","                             fields=(sourceLanguage, targetLanguage),\n","                             filter_pred=lambda x: len(x.__dict__['src']) <= 50)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dSfBltgd6yEA","colab_type":"code","colab":{}},"source":["# Build vocabulary for source and target languages using words\n","# with at least 2 occurences in dataset and limit vocab size to 30000\n","sourceLanguage.build_vocab(train_data, min_freq = 100)\n","targetLanguage.build_vocab(train_data, min_freq = 100)\n","# Use the cuda device if available\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"U4vNhHswDISn","colab_type":"code","colab":{}},"source":["BATCH_SIZE = 80\n","INPUT_DIM  = len(sourceLanguage.vocab) # Kx = Size of Source Vocabulary\n","OUTPUT_DIM = len(targetLanguage.vocab) # Ky = Size of Target Vocabulary\n","EMB_DIM = 256 # m = Dimension of Embedding\n","HID_DIM = 512 # n = Dimension of Hidden Units\n","MAXOUT_DIM = 400 # l = Dimension of Maxout Hidden Layer\n","ATT_HID_DIM = 1000 # n' = Number of Hidden Units in alignment model\n","MAX_LENGTH = 50 # Maximum length of sentence used"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2clFGjZ7_7t_","colab_type":"code","colab":{}},"source":["# Iterators that iterate through train, validation and test data\n","train_iterator = Iterator(\n","    train_data, \n","    batch_size = BATCH_SIZE,\n","    sort_key = lambda x: len(x.src),\n","    device = device\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2qrxH1ZCAWrB","colab_type":"code","colab":{}},"source":["# Encoder Layer\n","# Input:\n","#   1) source: source sentence\n","# Outputs: \n","#   1) encoder_outputs: the hidden states of the source sentence\n","#   2) hidden: the input to the first GRU of the decoder\n","class Encoder(nn.Module):\n","    def __init__(self, input_dimension, embedding_dimension, hidden_dimension):\n","        super().__init__() \n","        self.embedding = nn.Embedding(input_dimension, embedding_dimension)\n","        self.rnn = nn.GRU(embedding_dimension, hidden_dimension, bidirectional = True)\n","        # Monodirectional Implementation: \n","        # self.rnn = nn.GRU(embedding_dimension, hidden_dimension, bidirectional = False)\n","        self.fc = nn.Linear(hidden_dimension, hidden_dimension)\n","\n","    def forward(self, source):  \n","        # Embedding Layer\n","        embedded = self.embedding(source)\n","        # Bidirectional GRU-based RNN\n","        encoder_outputs, hidden = self.rnn(embedded)\n","        # Hidden layer pased as input to decoder\n","        hidden = torch.tanh(self.fc(hidden[1,:,:]))\n","        # Monodirectional Implementation:\n","        # hidden = torch.tanh(self.fc(hidden[0,:,:]))\n","        return encoder_outputs, hidden"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IaohLb_oAhF3","colab_type":"code","colab":{}},"source":["# Attention Layer\n","# Inputs: \n","#   1) hidden: previous hidden state of decoder\n","#   2) encoder_outputs: hidden states from the encoder\n","# Ouput:\n","#   1) Weights alpha_i_j\n","class Attention(nn.Module):\n","    def __init__(self, hidden_dimension, attention_hidden_dimension):\n","        super().__init__()\n","        self.attn = nn.Linear((hidden_dimension * 2) + hidden_dimension, attention_hidden_dimension)\n","        # Monodirectional Implementation:\n","        # self.attn = nn.Linear(hidden_dimension + hidden_dimension, attention_hidden_dimension)\n","        self.v = nn.Linear(attention_hidden_dimension, 1, bias = False)\n","        \n","    def forward(self, hidden, encoder_outputs):\n","        batch_size = encoder_outputs.shape[1]\n","        source_length = encoder_outputs.shape[0]\n","        # Repeat decoder hidden state source_length times\n","        # This is done to calculate the energy between the hidden state \n","        # and each of the encoder's source_length hidden states \n","        hidden = hidden.unsqueeze(1).repeat(1, source_length, 1)\n","        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n","        # Calculate alignment model (also known as energy)\n","        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim = 2)))\n","        # Single perceptron \n","        attention = self.v(energy).squeeze(2)\n","        # Return softmax of alignment model\n","        return F.softmax(attention, dim=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lv9BshuzAh9P","colab_type":"code","colab":{}},"source":["# Decoder Layer\n","# Inputs:\n","#   1) input: y_t-1 used to compute y_t\n","#   2) hidden: s_t-1 used to in layer t\n","#   3) encoder_outputs: hidden states from the encoder\n","# Outputs:\n","#   1) prediction: y_t\n","#   2) hidden: s_t\n","class Decoder(nn.Module):\n","    def __init__(self, output_dimension, embedding_dimension, hidden_dimension, attention, maxout_dimension):\n","        super().__init__()\n","        self.output_dimension = output_dimension\n","        self.maxout_dimension = maxout_dimension\n","        self.attention = attention\n","        self.embedding = nn.Embedding(output_dimension, embedding_dimension)\n","        self.rnn = nn.GRU((hidden_dimension * 2) + embedding_dimension , hidden_dimension)\n","        self.maxout = nn.Linear((hidden_dimension * 2) + hidden_dimension + embedding_dimension, 2 * maxout_dimension)\n","        self.fc_out = nn.Linear(maxout_dimension, output_dimension)\n","        \n","    def forward(self, input, hidden, encoder_outputs):        \n","        # Reshape Input\n","        input = input.unsqueeze(0)\n","        # Embedding Layer        \n","        embedded = self.embedding(input)\n","        # Attention Layer\n","        a = self.attention(hidden, encoder_outputs)\n","        # Reshape attention output\n","        a = a.unsqueeze(1)\n","        \n","        # Reshape encoder_outputs\n","        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n","        # Calculate context using encoder_outputs and attention output\n","        context = torch.bmm(a, encoder_outputs)\n","        # Reshape context\n","        context = context.permute(1, 0, 2) \n","        # Concatenate context and y_t-1\n","        rnn_input = torch.cat((embedded, context), dim = 2)\n","        \n","        # GRU-based RNN\n","        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n","\n","        assert (output == hidden).all()\n","        # Since output == hidden, use output. Can't use hidden because of a shaping issue\n","        # Essentially, they are the same tensor but one is [1,1,x] and the other is [1,x]\n","\n","        # Reshape tensors\n","        embedded = embedded.squeeze(0)\n","        output = output.squeeze(0)\n","        context = context.squeeze(0)\n","\n","        # Maxout layer\n","        t_init = self.maxout(torch.cat((output, context, embedded), dim = 1)) # Size 2xl\n","        batch_size = t_init.shape[0]\n","        t_init = t_init.view(batch_size ,self.maxout_dimension, 2)\n","        t, _ = torch.max(t_init,2)  \n","        t = t.view(batch_size,t.shape[1])  # Size l\n","        # FC layer\n","        prediction = self.fc_out(t)\n","        # Return prediciton y_t along with hidden state s_t\n","        return prediction, hidden.squeeze(0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"97aLY_IjAnoW","colab_type":"code","colab":{}},"source":["# Model Encapsulating all Layers\n","# Inputs: \n","#   1) src: source sentence\n","#   2) trg: target sentence\n","#   3) train: bool indicating if model currenlty used for training or evaluation\n","# Outputs:\n","#   1) outputs_train/outputs_evaluate: All the y_ts predicted by the model\n","class Seq2SeqBiDirectionalSearch(nn.Module):\n","    def __init__(self, encoder, decoder, max_length, device):\n","        super().__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.device = device\n","        self.max_length = max_length\n","    \n","    def forward(self, src, trg, train):\n","        batch_size = src.shape[1]\n","        target_length = trg.shape[0]\n","        target_vocab_size = self.decoder.output_dimension\n","        # Output tensors used to hold predictions, if train = 1 then outputs_train is used\n","        # with size target_length, however when evaluating (i.e. train = 0), outputs_evaluate\n","        # is used with size max_length\n","        outputs_train = torch.zeros(target_length, batch_size, target_vocab_size).to(self.device)\n","        outputs_evaluate = torch.zeros(self.max_length, batch_size, target_vocab_size).to(self.device)\n","        # Call encoder layer and get encoder_outputs and hidden\n","        encoder_outputs, hidden = self.encoder(src)\n","        \n","        input = trg[0,:] # SOS (Start-Of-Sentence) used as the first input y_1 \n","        \n","        # If in training phase, run decoder target_length times, with output\n","        # hidden used as s_t-1 to next stage t and decoder_output used as y_t-1\n","        if train == 1: # training \n","          for t in range(1, target_length):\n","              decoder_output, hidden = self.decoder(input, hidden, encoder_outputs)\n","              outputs_train[t] = decoder_output\n","              input = decoder_output.argmax(1)\n","          # Return decoder predictions\n","          return outputs_train\n","        # If in evaluation phase, run decoder till EOS predicted or till max_length\n","        # of sentence\n","        elif train == 0: # evaluate\n","          # Evaluate source sentences individually, i.e. batching not used\n","          for batch_idx in range(batch_size):\n","            input_temp = input[batch_idx].reshape(1)\n","            hidden_temp = hidden[batch_idx, :].reshape(1, hidden.shape[1])\n","            encoder_outputs_temp = encoder_outputs[:, batch_idx, :].reshape(encoder_outputs.shape[0], 1, encoder_outputs.shape[2])\n","            for t in range(1, self.max_length):                \n","                decoder_output, hidden_temp = self.decoder(input_temp, hidden_temp , encoder_outputs_temp )\n","                outputs_evaluate[t, batch_idx]= decoder_output\n","                input_temp = decoder_output.argmax(1)\n","                # If y_t = EOS return\n","                if targetLanguage.vocab.itos[input_temp] == targetLanguage.eos_token: \n","                  break\n","          # Return decoder predictions\n","          return outputs_evaluate"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hzkcjYc-A3ad","colab_type":"code","colab":{}},"source":["# Instantiate layers and model\n","enc = Encoder(INPUT_DIM, EMB_DIM, HID_DIM)\n","attn = Attention(HID_DIM,ATT_HID_DIM)\n","dec = Decoder(OUTPUT_DIM, EMB_DIM, HID_DIM, attn, MAXOUT_DIM)\n","model = Seq2SeqBiDirectionalSearch(enc, dec, MAX_LENGTH, device).to(device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AM-jjNTTBS5x","colab_type":"code","outputId":"21b129ea-926f-462a-af52-4eacc8ef4c83","executionInfo":{"status":"ok","timestamp":1586599475468,"user_tz":-330,"elapsed":2590,"user":{"displayName":"Abhinav Havaldar","photoUrl":"","userId":"17469083248397030696"}},"colab":{"base_uri":"https://localhost:8080/","height":306}},"source":["# Initialize weights\n","def init_weights(m):\n","    for name, param in m.named_parameters():\n","        if 'gru.weight_hh' in name:\n","            nn.init.orthogonal_(param.data)\n","        elif 'attn.weight' in name:\n","            nn.init.normal_(param.data, mean=0, std=0.001)\n","        elif 'v.weight' in name or 'bias' in name:\n","            nn.init.constant_(param.data, 0)\n","        else:\n","            nn.init.normal_(param.data, mean=0, std=0.01)\n","\n","model.apply(init_weights)"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Seq2SeqBiDirectionalSearch(\n","  (encoder): Encoder(\n","    (embedding): Embedding(33092, 256)\n","    (rnn): GRU(256, 512, bidirectional=True)\n","    (fc): Linear(in_features=512, out_features=512, bias=True)\n","  )\n","  (decoder): Decoder(\n","    (attention): Attention(\n","      (attn): Linear(in_features=1536, out_features=1000, bias=True)\n","      (v): Linear(in_features=1000, out_features=1, bias=False)\n","    )\n","    (embedding): Embedding(33092, 256)\n","    (rnn): GRU(1280, 512)\n","    (maxout): Linear(in_features=1792, out_features=800, bias=True)\n","    (fc_out): Linear(in_features=400, out_features=33092, bias=True)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"Ufe0mkRsBY7n","colab_type":"code","colab":{}},"source":["# Create Adadelta optimizer\n","optimizer = optim.Adadelta(model.parameters(), rho=0.95, eps=1e-06)\n","# Initialize cross entropy loss\n","TRG_PAD_IDX = targetLanguage.vocab.stoi[targetLanguage.pad_token]\n","criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4vOSJYb1BpSJ","colab_type":"code","colab":{}},"source":["# Train the model and compute training loss\n","def train(model, iterator, optimizer, criterion, clip):\n","    \n","    model.train()\n","    epoch_loss = 0\n","    \n","    # Loop through epoch\n","    for i, batch in enumerate(iterator):\n","      src = batch.src\n","      trg = batch.trg\n","      optimizer.zero_grad()\n","\n","      # Model with train = 1\n","      output = model(src, trg, 1)\n","      # Reshape Output and Target\n","      output_dim = output.shape[-1]\n","      output = output[1:].view(-1, output_dim)\n","      trg = trg[1:].view(-1)\n","\n","      # Compute loss \n","      loss = criterion(output, trg)\n","      # Backpropagation\n","      loss.backward()\n","      # Use gradient clipping\n","      torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n","      optimizer.step()\n","      epoch_loss += loss.item()\n","\n","    # Return average loss \n","    return epoch_loss / len(iterator)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"H-FEbNLZldG3","colab_type":"code","colab":{}},"source":["# Convert one-hot vectors to text\n","def one_hot_to_text(one_hot, languageModel, filter_unk=False):\n","  return [languageModel.vocab.itos[idx] for idx in one_hot if not (filter_unk and idx == 0)]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"z39ilF4gB4mT","colab_type":"code","colab":{}},"source":["# Train the model and compute blue score\n","def evaluate(model, iterator):\n","    \n","    model.eval()\n","    # Store Bleu score per sentence length\n","    counts = defaultdict(float)\n","    scores = defaultdict(float)\n","    epoch_bleu_score = 0\n","    \n","    with torch.no_grad():\n","        # Loop through epoch\n","        for i, batch in enumerate(iterator):\n","            src = batch.src\n","            trg = batch.trg\n","\n","            # Model with train = 1\n","            output = model(src, trg, 0)\n","            sentence_size, batch_size, vocab_size = output.shape\n","            \n","            # Compute Bleu Score for sentences in current batch\n","            for batch_idx in range(batch_size):\n","                probs = F.softmax(output[:,batch_idx,:], 1)\n","                _, sentence_by_idx = probs.max(axis=1)                      \n","                score = sentence_bleu([one_hot_to_text(trg[:,batch_idx], targetLanguage)], one_hot_to_text(sentence_by_idx, targetLanguage))\n","                length = len([1 for word in src[:,batch_idx] if word != targetLanguage.vocab.stoi[targetLanguage.unk_token]])\n","                counts[length] += 1\n","                scores[length] += score\n","                epoch_bleu_score += score\n","    # Return bleu score average for each sentence length + total bleu score for epoch\n","    return {length: scores[length] / counts[length] for length in scores}, epoch_bleu_score"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IE0gvylSB90s","colab_type":"code","colab":{}},"source":["# Calculate time spent by a single epoch\n","def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UNl3GcwMB-qF","colab_type":"code","colab":{}},"source":["# Number of Epochs\n","N_EPOCHS = 5\n","# Gradient Clipping \n","CLIP = 1\n","\n","model.load_state_dict(torch.load(f'/content/gdrive/My Drive/models/attention-model-bidirectional-3.pt'))\n","model.eval()\n","\n","for epoch in range(4, N_EPOCHS):\n","    start_time = time.time()\n","    train_loss = train(model, train_iterator, optimizer, criterion, CLIP) \n","    end_time = time.time()\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","\n","    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss: }')\n","    torch.save(model.state_dict(), f'/content/gdrive/My Drive/models/attention-model-bidirectional-{epoch}.pt')\n","    model.load_state_dict(torch.load(f'/content/gdrive/My Drive/models/attention-model-bidirectional-{epoch}.pt'))\n","    model.eval()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"f1Ce-PrjsZGr","colab_type":"code","colab":{}},"source":["# Plot Training Loss\n","plt.title(\"Training Loss\") \n","plt.xlabel(\"Number of Epochs\") \n","plt.ylabel(\"Training Loss\") \n","plt.plot(range(len(training_loss_array)), training_loss_array)\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EaiPKUIiYo_1","colab_type":"code","colab":{}},"source":["# Load and evaluate models on test data\n","model.load_state_dict(torch.load(f'/content/gdrive/My Drive/control_and_attention_model/attention-model-bidirectional-1.pt'))\n","bleu_scores, epoch_bleu_score = evaluate(model, test_iterator)\n","\n","# Plot Bleu Scores as a function of sentence length\n","plt.title(\"Bleu Scores\") \n","plt.xlabel(\"Sentence Length\") \n","plt.ylabel(\"Bleu Score\") \n","lists = sorted(bleu_scores.items()) \n","x, y = zip(*lists) \n","plt.plot(x, y)\n","plt.show()\n","plt.savefig('bleu_scores.png')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7CPQ292JGjhI","colab_type":"code","outputId":"001ab6a3-dfdc-4542-d684-7a053f6d8a1d","executionInfo":{"status":"ok","timestamp":1586426673995,"user_tz":-60,"elapsed":8347,"user":{"displayName":"Sherif Fawzy","photoUrl":"","userId":"13260263750555417643"}},"colab":{"base_uri":"https://localhost:8080/","height":211}},"source":["!wget \"https://www.statmt.org/wmt14/test.tgz\" "],"execution_count":0,"outputs":[{"output_type":"stream","text":["--2020-04-09 10:04:31--  https://www.statmt.org/wmt14/test.tgz\n","Resolving www.statmt.org (www.statmt.org)... 129.215.197.184\n","Connecting to www.statmt.org (www.statmt.org)|129.215.197.184|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 5352747 (5.1M) [application/x-gzip]\n","Saving to: ‘test.tgz’\n","\n","test.tgz            100%[===================>]   5.10M  5.44MB/s    in 0.9s    \n","\n","2020-04-09 10:04:33 (5.44 MB/s) - ‘test.tgz’ saved [5352747/5352747]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RkxF78MtGoOF","colab_type":"code","colab":{}},"source":["!ls\n","!tar -xvzf test.tgz\n","!ls"],"execution_count":0,"outputs":[]}]}