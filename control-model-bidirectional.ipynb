{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"control-model-bidirectional.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"5eUhX373CVqc","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torchtext.datasets import TranslationDataset, IWSLT\n","from torchtext.data import Field, Iterator, Dataset\n","import spacy\n","import numpy as np\n","import random\n","import math\n","import time\n","from collections import defaultdict\n","from nltk.translate.bleu_score import sentence_bleu"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JGE-IhBd8eYk","colab_type":"code","colab":{}},"source":["# Random seeds defined for the sake of reproducibility\n","SEED = 1234\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y2LPt4ohI6W4","colab_type":"text"},"source":["## Data Loading\n","Loads data from google drive and builds the vocabulary used in the one hot vector."]},{"cell_type":"code","metadata":{"id":"251TtINf8fM0","colab_type":"code","outputId":"7691c2c4-08b3-4f6e-c148-521fbdf80cd9","executionInfo":{"status":"ok","timestamp":1586397580466,"user_tz":-330,"elapsed":37351,"user":{"displayName":"Abhinav Havaldar","photoUrl":"","userId":"17469083248397030696"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OtAYgTaKLgPF","colab_type":"code","colab":{}},"source":["%%capture\n","sos_token='<sos>'\n","eos_token='<eos>'\n","pad_token='<pad>'\n","unk_token='<unk>'\n","\n","def tokenize(text):\n","    return text.split()\n","\n","# while the paper does not lower case all the words, we do in order to minimize \n","# the size of the vocabulary due to more limited resources.\n","sourceLanguage = targetLanguage = Field(sequential=True, \n","                                        use_vocab=True, \n","                                        init_token=sos_token, \n","                                        eos_token=eos_token, \n","                                        fix_length=None, \n","                                        dtype=torch.long, \n","                                        lower=True, \n","                                        tokenize=tokenize,\n","                                        pad_token=pad_token, \n","                                        unk_token=unk_token)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4KPr4D9q8nyI","colab_type":"code","colab":{}},"source":["# Manually filtering out all sentences that are longer than 50 as is done in\n","# the proposed training set in the paper\n","dataset = TranslationDataset(\"/content/gdrive/My Drive/data/europarl-v7.fr-en\", \n","                             exts=('.en', '.fr'), \n","                             fields=(sourceLanguage, targetLanguage),\n","                             filter_pred=lambda x: len(x.__dict__['src']) <= 50) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-ji98My9qLh9","colab_type":"code","colab":{}},"source":["# Using a minimum frequency here is another method used to reduce the size of \n","# the model while ensuring the most frequent words are accounted for.\n","sourceLanguage.build_vocab(dataset, min_freq = 100)\n","targetLanguage.build_vocab(dataset, min_freq = 100)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Vd9xS0iBJKds","colab_type":"text"},"source":["## Constants\n","Defines the dimensions used for the model."]},{"cell_type":"code","metadata":{"id":"7rAo1K5I8vZY","colab_type":"code","colab":{}},"source":["# Usefull constant for moving tensors onto the appropriate device\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","BATCH_SIZE  = 80\n","INPUT_DIM   = len(sourceLanguage.vocab)\n","OUTPUT_DIM  = len(targetLanguage.vocab)\n","EMB_DIM     = 256\n","HID_DIM     = 512\n","MAXOUT_DIM  = 400\n","MAX_LENGTH  = 50"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5ClltuFX8xdm","colab_type":"code","colab":{}},"source":["train_iterator = Iterator(\n","    dataset, \n","    batch_size = BATCH_SIZE,\n","    sort_key = lambda x: len(x.src), \n","    device = device\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TDWE3gx6JUuT","colab_type":"text"},"source":["## Model Definition\n","Defines the encoder, decoder, and the ensemble sequence to sequence translation model. "]},{"cell_type":"code","metadata":{"id":"2vcd40p6Cd-T","colab_type":"code","colab":{}},"source":["class EncoderRNNEncDecBiDirectional(nn.Module):\n","    def __init__(self, input_dim, emb_dim, hid_dim):\n","        super(EncoderRNNEncDecBiDirectional, self).__init__()\n","        self.embedding  = nn.Embedding(input_dim, emb_dim)\n","        self.rnn        = nn.GRU(emb_dim, hid_dim, bidirectional=True)\n","        self.fc_out     = nn.Linear(hid_dim, hid_dim) # fully connected out layer\n","        self.activation = nn.Tanh() # activation for the final layer\n","        \n","    def forward(self, input):\n","        output          = self.embedding(input)\n","        output, hidden  = self.rnn(output)\n","        output          = self.activation(self.fc_out(hidden[1,:,:]))\n","        output          = output.unsqueeze(0)\n","        return output\n","\n","class DecoderRNNEncDecBiDirectional(nn.Module):\n","    def __init__(self, output_dim, emb_dim, hid_dim, max_dim):\n","        super(DecoderRNNEncDecBiDirectional, self).__init__()\n","        self.embedding  = nn.Embedding(output_dim, emb_dim)\n","        self.rnn        = nn.GRU(emb_dim + hid_dim, hid_dim)\n","        self.max_dim    = max_dim\n","        self.max_out    = nn.Linear(emb_dim + hid_dim * 2, 2 * max_dim)\n","        self.out        = nn.Linear(max_dim, output_dim)\n","\n","    def forward(self, input, hidden, context):\n","        embedded        = self.embedding(input)                     \n","        output          = torch.cat((embedded, context), dim = 2)\n","        _, hidden       = self.rnn(output, hidden)\n","        output          = torch.cat((embedded.squeeze(0), \n","                                     hidden.squeeze(0), \n","                                     context.squeeze(0)), \n","                                    dim = 1)\n","        output          = self.max_out(output)\n","        output          = output.view(input.shape[1], self.max_dim, 2)\n","        output, _       = torch.max(output, 2) # acitvation for maxout layer\n","        output          = self.out(output)\n","        return output, hidden\n","\n","class Seq2SeqEncDecBiDirectional(nn.Module):\n","    def __init__(self, input_dim, emb_dim, hid_dim, output_dim, max_dim):\n","        super(Seq2SeqEncDecBiDirectional, self).__init__() \n","        self.fc_in      = nn.Linear(hid_dim, hid_dim) # fully connected layer for context\n","        self.fc_act     = nn.Tanh() # activation for context\n","        self.encoder    = EncoderRNNEncDecBiDirectional(input_dim, emb_dim, hid_dim)\n","        self.decoder    = DecoderRNNEncDecBiDirectional(output_dim, emb_dim, hid_dim, max_dim)\n","        self.output_dim = output_dim\n","    \n","    def forward(self, src, trg, is_train=False):\n","        context         = self.encoder(src)\n","        decoder_hidden  = self.fc_in(context.squeeze(0))\n","        decoder_hidden  = self.fc_act(decoder_hidden).unsqueeze(0)\n","        outputs         = torch.zeros(trg.shape[0], \n","                                      trg.shape[1], \n","                                      self.output_dim).to(device)\n","        input           = trg[0]\n","        for t in range(1, trg.shape[0]):\n","            decoder_output, decoder_hidden = self.decoder(input.unsqueeze(0), \n","                                                          decoder_hidden, \n","                                                          context)\n","            outputs[t] = decoder_output\n","\n","            # if in training use the actual values else use predicted values\n","            input = trg[t] if is_train else decoder_output.argmax(1)\n","        return outputs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YIaTqBqaIpbM","colab_type":"code","colab":{}},"source":["model       = Seq2SeqEncDecBiDirectional(INPUT_DIM, EMB_DIM, HID_DIM, OUTPUT_DIM, MAXOUT_DIM).to(device)\n","optimizer   = optim.Adadelta(model.parameters(), rho=0.95, eps=1e-06)\n","TRG_PAD_IDX = targetLanguage.vocab.stoi[targetLanguage.pad_token]\n","\n","# Ignore differences on padding since these aren't indicative of error\n","criterion   = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7VFS9TB2KEgl","colab_type":"text"},"source":["## Training Utils\n","Utility methods to be used during the training phase. "]},{"cell_type":"code","metadata":{"id":"bv1PIyoHr__5","colab_type":"code","colab":{}},"source":["def train(model, iterator, optimizer, criterion, max_length=MAX_LENGTH):\n","    model.train()\n","    epoch_loss = 0.0\n","    for i, batch in enumerate(iterator):\n","        # ignore sentences that are too large\n","        if batch.src.shape[0] > max_length: continue\n","        optimizer.zero_grad()\n","        src, trg    = batch.src.to(device), batch.trg.to(device)\n","        outputs     = model(src, trg, is_train=True)\n","        output_dim  = outputs.shape[-1]\n","        outputs     = outputs[1:].view(-1, output_dim)\n","        trg         = trg[1:].view(-1)\n","        loss        = criterion(outputs, trg)\n","        loss.backward()\n","        optimizer.step()\n","        epoch_loss += loss.item()\n","    return epoch_loss / len(iterator) # average loss"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GCReainZ8Jgr","colab_type":"code","colab":{}},"source":["def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-f8l8IemJ1u2","colab_type":"text"},"source":["## Training\n","\n","Defines the training procedure and checkpoint model saving to ensure no loss of progress in the instance of a timeout from colab."]},{"cell_type":"code","metadata":{"id":"crDPzH4IIvBR","colab_type":"code","outputId":"57b0e41e-1599-4a3b-8315-5d1668def2a2","executionInfo":{"status":"ok","timestamp":1586425967654,"user_tz":-330,"elapsed":1486101,"user":{"displayName":"Abhinav Havaldar","photoUrl":"","userId":"17469083248397030696"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["N_EPOCHS = 5\n","\n","for epoch in range(N_EPOCHS):\n","    train_iterator.init_epoch() # Processes like shuffling that happen before epoch.\n","    start_time = time.time()\n","    train_loss = train(model, train_iterator, optimizer, criterion) \n","    end_time = time.time()\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss: }')\n","\n","    # Checkpoint to ensure progrerss isn't lost.\n","    torch.save(model.state_dict(), f'/content/gdrive/My Drive/models/control-model-bidirectional-{epoch}.pt')\n","    model.load_state_dict(torch.load(f'/content/gdrive/My Drive/models/control-model-bidirectional-{epoch}.pt'))\n","    model.eval()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch: 01 | Time: 94m 21s\n","\tTrain Loss:  1.6890117076940787\n","Epoch: 02 | Time: 94m 0s\n","\tTrain Loss:  1.3272293888111024\n","Epoch: 03 | Time: 94m 23s\n","\tTrain Loss:  1.2192805539328617\n","Epoch: 04 | Time: 94m 0s\n","\tTrain Loss:  1.1602228156215846\n","Epoch: 05 | Time: 92m 56s\n","\tTrain Loss:  1.1000997231662901\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Y0KyFB0e0LPB","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}