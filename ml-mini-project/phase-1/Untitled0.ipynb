{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled0.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNhuty/3G+/mbSiq6873V7C"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"G2UE217JTqDI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"14be85b5-cd0d-4558-9d8c-d9de902d435f","executionInfo":{"status":"ok","timestamp":1583322258741,"user_tz":0,"elapsed":4243,"user":{"displayName":"Abhinav Havaldar","photoUrl":"","userId":"17469083248397030696"}}},"source":["!pip install nltk\n"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vU-p1yz9Tw63","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2lAWG3mBUpbG","colab_type":"code","colab":{}},"source":["from nltk.translate.bleu_score import sentence_bleu\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torchtext.datasets import TranslationDataset, Multi30k\n","from torchtext.data import Field, BucketIterator\n","import spacy\n","import numpy as np\n","import random\n","import math\n","import time"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1QGZljuhVqoK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":394},"outputId":"50aa7a38-8fcb-4d38-9227-1f65556b547e","executionInfo":{"status":"ok","timestamp":1583323421956,"user_tz":0,"elapsed":11294,"user":{"displayName":"Abhinav Havaldar","photoUrl":"","userId":"17469083248397030696"}}},"source":["!python -m spacy download en\n","!python -m spacy download fr\n","!python -m spacy download de\n","\n","spacy_en = spacy.load('en')\n","spacy_fr = spacy.load('fr')\n","spacy_de = spacy.load('de')\n","\n","def tokenize_en(text):\n","    return [tok.text for tok in spacy_en.tokenizer(text)]\n","\n","def tokenize_de(text):\n","    return [tok.text for tok in spacy_de.tokenizer(text)]\n","\n","def tokenize_fr(text):\n","    return [tok.text for tok in spacy_fr.tokenizer(text)]\n","\n","    \n","sourceLanguage = Field(tokenize = tokenize_en, \n","            init_token = '<sos>', \n","            eos_token = '<eos>', \n","            lower = True)\n","\n","targetLanguage = Field(tokenize = tokenize_fr, \n","            init_token = '<sos>', \n","            eos_token = '<eos>', \n","            lower = True)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: en_core_web_sm==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz#egg=en_core_web_sm==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('en_core_web_sm')\n","\u001b[38;5;2m✔ Linking successful\u001b[0m\n","/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n","/usr/local/lib/python3.6/dist-packages/spacy/data/en\n","You can now load the model via spacy.load('en')\n","Requirement already satisfied: fr_core_news_sm==2.1.0 from https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-2.1.0/fr_core_news_sm-2.1.0.tar.gz#egg=fr_core_news_sm==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('fr_core_news_sm')\n","\u001b[38;5;2m✔ Linking successful\u001b[0m\n","/usr/local/lib/python3.6/dist-packages/fr_core_news_sm -->\n","/usr/local/lib/python3.6/dist-packages/spacy/data/fr\n","You can now load the model via spacy.load('fr')\n","Requirement already satisfied: de_core_news_sm==2.1.0 from https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.1.0/de_core_news_sm-2.1.0.tar.gz#egg=de_core_news_sm==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('de_core_news_sm')\n","\u001b[38;5;2m✔ Linking successful\u001b[0m\n","/usr/local/lib/python3.6/dist-packages/de_core_news_sm -->\n","/usr/local/lib/python3.6/dist-packages/spacy/data/de\n","You can now load the model via spacy.load('de')\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"395gFQ8QWE2P","colab_type":"code","colab":{}},"source":["train_data, valid_data, test_data = Multi30k.splits(exts = ('.en', '.de'), fields = (sourceLanguage, targetLanguage))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OkQHxLruauvT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":493},"outputId":"542953c9-a1db-49d9-8ced-f2a56e157466","executionInfo":{"status":"ok","timestamp":1583323999293,"user_tz":0,"elapsed":426,"user":{"displayName":"Abhinav Havaldar","photoUrl":"","userId":"17469083248397030696"}}},"source":["help(valid_data[0])"],"execution_count":41,"outputs":[{"output_type":"stream","text":["Help on Example in module torchtext.data.example object:\n","\n","class Example(builtins.object)\n"," |  Defines a single training or test example.\n"," |  \n"," |  Stores each column of the example as an attribute.\n"," |  \n"," |  Class methods defined here:\n"," |  \n"," |  fromCSV(data, fields, field_to_index=None) from builtins.type\n"," |  \n"," |  fromJSON(data, fields) from builtins.type\n"," |  \n"," |  fromdict(data, fields) from builtins.type\n"," |  \n"," |  fromlist(data, fields) from builtins.type\n"," |  \n"," |  fromtree(data, fields, subtrees=False) from builtins.type\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Data descriptors defined here:\n"," |  \n"," |  __dict__\n"," |      dictionary for instance variables (if defined)\n"," |  \n"," |  __weakref__\n"," |      list of weak references to the object (if defined)\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gE8eisUncKa3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"df3e79e3-316d-46e7-a5bb-1e6b6b43acb1","executionInfo":{"status":"ok","timestamp":1583323843829,"user_tz":0,"elapsed":492,"user":{"displayName":"Abhinav Havaldar","photoUrl":"","userId":"17469083248397030696"}}},"source":[""],"execution_count":35,"outputs":[{"output_type":"stream","text":["Help on Field in module torchtext.data.field object:\n","\n","class Field(RawField)\n"," |  Defines a datatype together with instructions for converting to Tensor.\n"," |  \n"," |  Field class models common text processing datatypes that can be represented\n"," |  by tensors.  It holds a Vocab object that defines the set of possible values\n"," |  for elements of the field and their corresponding numerical representations.\n"," |  The Field object also holds other parameters relating to how a datatype\n"," |  should be numericalized, such as a tokenization method and the kind of\n"," |  Tensor that should be produced.\n"," |  \n"," |  If a Field is shared between two columns in a dataset (e.g., question and\n"," |  answer in a QA dataset), then they will have a shared vocabulary.\n"," |  \n"," |  Attributes:\n"," |      sequential: Whether the datatype represents sequential data. If False,\n"," |          no tokenization is applied. Default: True.\n"," |      use_vocab: Whether to use a Vocab object. If False, the data in this\n"," |          field should already be numerical. Default: True.\n"," |      init_token: A token that will be prepended to every example using this\n"," |          field, or None for no initial token. Default: None.\n"," |      eos_token: A token that will be appended to every example using this\n"," |          field, or None for no end-of-sentence token. Default: None.\n"," |      fix_length: A fixed length that all examples using this field will be\n"," |          padded to, or None for flexible sequence lengths. Default: None.\n"," |      dtype: The torch.dtype class that represents a batch of examples\n"," |          of this kind of data. Default: torch.long.\n"," |      preprocessing: The Pipeline that will be applied to examples\n"," |          using this field after tokenizing but before numericalizing. Many\n"," |          Datasets replace this attribute with a custom preprocessor.\n"," |          Default: None.\n"," |      postprocessing: A Pipeline that will be applied to examples using\n"," |          this field after numericalizing but before the numbers are turned\n"," |          into a Tensor. The pipeline function takes the batch as a list, and\n"," |          the field's Vocab.\n"," |          Default: None.\n"," |      lower: Whether to lowercase the text in this field. Default: False.\n"," |      tokenize: The function used to tokenize strings using this field into\n"," |          sequential examples. If \"spacy\", the SpaCy tokenizer is\n"," |          used. If a non-serializable function is passed as an argument,\n"," |          the field will not be able to be serialized. Default: string.split.\n"," |      tokenizer_language: The language of the tokenizer to be constructed.\n"," |          Various languages currently supported only in SpaCy.\n"," |      include_lengths: Whether to return a tuple of a padded minibatch and\n"," |          a list containing the lengths of each examples, or just a padded\n"," |          minibatch. Default: False.\n"," |      batch_first: Whether to produce tensors with the batch dimension first.\n"," |          Default: False.\n"," |      pad_token: The string token used as padding. Default: \"<pad>\".\n"," |      unk_token: The string token used to represent OOV words. Default: \"<unk>\".\n"," |      pad_first: Do the padding of the sequence at the beginning. Default: False.\n"," |      truncate_first: Do the truncating of the sequence at the beginning. Default: False\n"," |      stop_words: Tokens to discard during the preprocessing step. Default: None\n"," |      is_target: Whether this field is a target variable.\n"," |          Affects iteration over batches. Default: False\n"," |  \n"," |  Method resolution order:\n"," |      Field\n"," |      RawField\n"," |      builtins.object\n"," |  \n"," |  Methods defined here:\n"," |  \n"," |  __eq__(self, other)\n"," |      Return self==value.\n"," |  \n"," |  __getstate__(self)\n"," |  \n"," |  __hash__(self)\n"," |      Return hash(self).\n"," |  \n"," |  __init__(self, sequential=True, use_vocab=True, init_token=None, eos_token=None, fix_length=None, dtype=torch.int64, preprocessing=None, postprocessing=None, lower=False, tokenize=None, tokenizer_language='en', include_lengths=False, batch_first=False, pad_token='<pad>', unk_token='<unk>', pad_first=False, truncate_first=False, stop_words=None, is_target=False)\n"," |      Initialize self.  See help(type(self)) for accurate signature.\n"," |  \n"," |  __setstate__(self, state)\n"," |  \n"," |  build_vocab(self, *args, **kwargs)\n"," |      Construct the Vocab object for this field from one or more datasets.\n"," |      \n"," |      Arguments:\n"," |          Positional arguments: Dataset objects or other iterable data\n"," |              sources from which to construct the Vocab object that\n"," |              represents the set of possible values for this field. If\n"," |              a Dataset object is provided, all columns corresponding\n"," |              to this field are used; individual columns can also be\n"," |              provided directly.\n"," |          Remaining keyword arguments: Passed to the constructor of Vocab.\n"," |  \n"," |  numericalize(self, arr, device=None)\n"," |      Turn a batch of examples that use this field into a Variable.\n"," |      \n"," |      If the field has include_lengths=True, a tensor of lengths will be\n"," |      included in the return value.\n"," |      \n"," |      Arguments:\n"," |          arr (List[List[str]], or tuple of (List[List[str]], List[int])):\n"," |              List of tokenized and padded examples, or tuple of List of\n"," |              tokenized and padded examples and List of lengths of each\n"," |              example if self.include_lengths is True.\n"," |          device (str or torch.device): A string or instance of `torch.device`\n"," |              specifying which device the Variables are going to be created on.\n"," |              If left as default, the tensors will be created on cpu. Default: None.\n"," |  \n"," |  pad(self, minibatch)\n"," |      Pad a batch of examples using this field.\n"," |      \n"," |      Pads to self.fix_length if provided, otherwise pads to the length of\n"," |      the longest example in the batch. Prepends self.init_token and appends\n"," |      self.eos_token if those attributes are not None. Returns a tuple of the\n"," |      padded list and a list containing lengths of each example if\n"," |      `self.include_lengths` is `True` and `self.sequential` is `True`, else just\n"," |      returns the padded list. If `self.sequential` is `False`, no padding is applied.\n"," |  \n"," |  preprocess(self, x)\n"," |      Load a single example using this field, tokenizing if necessary.\n"," |      \n"," |      If the input is a Python 2 `str`, it will be converted to Unicode\n"," |      first. If `sequential=True`, it will be tokenized. Then the input\n"," |      will be optionally lowercased and passed to the user-provided\n"," |      `preprocessing` Pipeline.\n"," |  \n"," |  process(self, batch, device=None)\n"," |      Process a list of examples to create a torch.Tensor.\n"," |      \n"," |      Pad, numericalize, and postprocess a batch and create a tensor.\n"," |      \n"," |      Args:\n"," |          batch (list(object)): A list of object from a batch of examples.\n"," |      Returns:\n"," |          torch.autograd.Variable: Processed object given the input\n"," |          and custom postprocessing Pipeline.\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Data and other attributes defined here:\n"," |  \n"," |  dtypes = {torch.float32: <class 'float'>, torch.float64: <class 'float...\n"," |  \n"," |  ignore = ['dtype', 'tokenize']\n"," |  \n"," |  vocab_cls = <class 'torchtext.vocab.Vocab'>\n"," |      Defines a vocabulary object that will be used to numericalize a field.\n"," |      \n"," |      Attributes:\n"," |          freqs: A collections.Counter object holding the frequencies of tokens\n"," |              in the data used to build the Vocab.\n"," |          stoi: A collections.defaultdict instance mapping token strings to\n"," |              numerical identifiers.\n"," |          itos: A list of token strings indexed by their numerical identifiers.\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Data descriptors inherited from RawField:\n"," |  \n"," |  __dict__\n"," |      dictionary for instance variables (if defined)\n"," |  \n"," |  __weakref__\n"," |      list of weak references to the object (if defined)\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"z0UF-Pq0gGuI","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"159oUGS0dFx8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":187},"outputId":"938f7103-fdab-43ff-bd0e-9e8b199d5cb7","executionInfo":{"status":"ok","timestamp":1583324782473,"user_tz":0,"elapsed":512,"user":{"displayName":"Abhinav Havaldar","photoUrl":"","userId":"17469083248397030696"}}},"source":["valid_data[0].src, valid_data[0].trg"],"execution_count":48,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(['a', 'group', 'of', 'men', 'are', 'loading', 'cotton', 'onto', 'a', 'truck'],\n"," ['eine',\n","  'gruppe',\n","  'von',\n","  'männern',\n","  'lädt',\n","  'baumwolle',\n","  'auf',\n","  'einen',\n","  'lastwagen'])"]},"metadata":{"tags":[]},"execution_count":48}]},{"cell_type":"code","metadata":{"id":"zLCqppe-NJS1","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}