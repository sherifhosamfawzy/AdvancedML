{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"control-model-monodirectional.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"El7YpBIELHq2","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torchtext.datasets import TranslationDataset, IWSLT\n","from torchtext.data import Field, Iterator\n","import spacy\n","import numpy as np\n","import random\n","import math\n","import time\n","from collections import defaultdict\n","from nltk.translate.bleu_score import sentence_bleu\n","import gc"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"895j6EPt1Bhc","colab_type":"text"},"source":["## Seeding\n","Specify seeds for all random processes to ensure reproducibility."]},{"cell_type":"code","metadata":{"id":"pfxys7EfLfCf","colab_type":"code","colab":{}},"source":["SEED = 1234\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B7OEvtdj1Sqa","colab_type":"text"},"source":["## Load Data\n","The data is maintained in a google drive at ```My Drive/data/*```. The following sections specifies how to load this data into the appropriate dataset object and fields. Only the europarl section of the WMT14 dataset is used due to compute limitations."]},{"cell_type":"code","metadata":{"id":"KXB9kcr6Sggu","colab_type":"code","outputId":"423d0c7a-4816-4b30-9ba3-a35759c2165b","executionInfo":{"status":"ok","timestamp":1587389808371,"user_tz":-330,"elapsed":37913,"user":{"displayName":"Abhinav Havaldar","photoUrl":"","userId":"17469083248397030696"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MpVLCfgKLlGX","colab_type":"code","colab":{}},"source":["# creating torchtext datasets\n","sos_token='<sos>'\n","eos_token='<eos>'\n","pad_token='<pad>'\n","unk_token='<unk>'\n","\n","def tokenize(text):\n","    return text.split()\n","\n","# The paper originally maintains case however this increases the size of the \n","# vocabulary and hence we chose against this method.\n","sourceLanguage = targetLanguage = Field(sequential=True, \n","                                        use_vocab=True, \n","                                        init_token=sos_token, \n","                                        eos_token=eos_token, \n","                                        fix_length=None, \n","                                        dtype=torch.long, \n","                                        lower=True, \n","                                        tokenize=tokenize,\n","                                        pad_token=pad_token, \n","                                        unk_token=unk_token)\n","\n","# Filters out sentences longer than 50 in the training data.\n","dataset = TranslationDataset(\"/content/gdrive/My Drive/data/europarl-v7.fr-en\", \n","                             exts=('.en', '.fr'), \n","                             fields=(sourceLanguage, targetLanguage),\n","                             filter_pred=lambda x: len(x.__dict__['src']) <= 50)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gFwzGg3pTXQX","colab_type":"code","colab":{}},"source":["sourceLanguage.build_vocab(dataset, min_freq = 2, max_size = 30000)    \n","targetLanguage.build_vocab(dataset, min_freq = 2, max_size = 30000)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AVE_TmgcU0C6","colab_type":"code","colab":{}},"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","BATCH_SIZE = 80\n","INPUT_DIM  = len(sourceLanguage.vocab)\n","OUTPUT_DIM = len(targetLanguage.vocab) \n","EMB_DIM = 256\n","HID_DIM = 512\n","MAXOUT_DIM = 400\n","ATT_HID_DIM = 1000\n","MAX_LENGTH = 50"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cNi7XW1IViJB","colab_type":"code","colab":{}},"source":["train_iterator = Iterator(\n","    dataset, \n","    batch_size = BATCH_SIZE,\n","    sort_key = lambda x: len(x.src),\n","    device = device\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yJtxq7gKnxSz","colab_type":"text"},"source":["## ih"]},{"cell_type":"code","metadata":{"id":"VDQqXQvV2xTe","colab_type":"code","colab":{}},"source":["class EncoderRNNEncDec(nn.Module):\n","    def __init__(self, input_dim, emb_dim, hid_dim):\n","        super(EncoderRNNEncDec, self).__init__()\n","        self.embedding  = nn.Embedding(input_dim, emb_dim)\n","        self.rnn        = nn.GRU(emb_dim, hid_dim)\n","        self.fc_out     = nn.Linear(hid_dim, hid_dim)\n","        self.activation = nn.Tanh()\n","        \n","    def forward(self, input):\n","        output          = self.embedding(input)\n","        output, hidden  = self.rnn(output)\n","        output          = self.activation(self.fc_out(hidden.squeeze(0)))\n","        output          = output.unsqueeze(0)\n","        return output\n","\n","class DecoderRNNEncDec(nn.Module):\n","    def __init__(self, output_dim, emb_dim, hid_dim, max_dim):\n","        super(DecoderRNNEncDec, self).__init__()\n","        self.embedding  = nn.Embedding(output_dim, emb_dim)\n","        self.rnn        = nn.GRU(emb_dim + hid_dim, hid_dim)\n","        self.max_dim    = max_dim\n","        self.max_out    = nn.Linear(emb_dim + hid_dim * 2, 2 * max_dim)\n","        self.out        = nn.Linear(max_dim, output_dim)\n","\n","    def forward(self, input, hidden, context):\n","        embedded        = self.embedding(input)                     \n","        output          = torch.cat((embedded, context), dim = 2)\n","        _, hidden       = self.rnn(output, hidden)\n","        output          = torch.cat((embedded.squeeze(0), \n","                                     hidden.squeeze(0), \n","                                     context.squeeze(0)), \n","                                    dim = 1)\n","        output          = self.max_out(output)\n","        output          = output.view(input.shape[1], self.max_dim, 2)\n","        output, _       = torch.max(output, 2)\n","        output          = self.out(output)\n","        return output, hidden\n","\n","class Seq2Seq(nn.Module):\n","    def __init__(self, input_dim, emb_dim, hid_dim, output_dim, max_dim):\n","        super(Seq2Seq, self).__init__()\n","        self.fc_in      = nn.Linear(hid_dim, hid_dim)\n","        self.fc_act     = nn.Tanh()\n","        self.encoder    = EncoderRNNEncDec(input_dim, emb_dim, hid_dim)\n","        self.decoder    = DecoderRNNEncDec(output_dim, emb_dim, hid_dim, max_dim)\n","        self.output_dim = output_dim\n","    \n","    def forward(self, src, trg, is_train=False):\n","        context         = self.encoder(src)\n","        decoder_hidden  = self.fc_in(context.squeeze(0))\n","        decoder_hidden  = self.fc_act(decoder_hidden).unsqueeze(0)\n","        outputs         = torch.zeros(trg.shape[0], \n","                                      trg.shape[1], \n","                                      self.output_dim).to(device)\n","        input           = trg[0]\n","        for t in range(1, trg.shape[0]):\n","            decoder_output, decoder_hidden = self.decoder(input.unsqueeze(0), \n","                                                          decoder_hidden, \n","                                                          context)\n","            outputs[t] = decoder_output\n","            input = trg[t] if is_train else decoder_output.argmax(1)\n","        return outputs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4_j6E1b03W3T","colab_type":"code","colab":{}},"source":["model       = Seq2Seq(INPUT_DIM, EMB_DIM, HID_DIM, OUTPUT_DIM, MAXOUT_DIM).to(device)\n","optimizer   = optim.Adadelta(model.parameters(), rho=0.95, eps=1e-06)\n","TRG_PAD_IDX = targetLanguage.vocab.stoi[targetLanguage.pad_token]\n","criterion   = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2gxHEm-i3h5C","colab_type":"code","colab":{}},"source":["def train(model, iterator, optimizer, criterion):\n","    model.train()\n","    epoch_loss = 0.0\n","    for i, batch in enumerate(iterator):\n","        optimizer.zero_grad()\n","        src, trg    = batch.src, batch.trg\n","        outputs     = model(src, trg, is_train=True)\n","        output_dim  = outputs.shape[-1]\n","        outputs     = outputs[1:].view(-1, output_dim) # Reshape to match trg\n","        trg         = trg[1:].view(-1) # Ignore the init token.\n","        loss        = criterion(outputs, trg)\n","        loss.backward()\n","        optimizer.step()\n","        epoch_loss += loss.item()\n","    return epoch_loss / len(iterator)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xvLJVx-Z3rtn","colab_type":"code","colab":{}},"source":["# Convenience to get runtime for training.\n","def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"99OhRmMikTEx","colab_type":"code","outputId":"4a2142c4-7412-44fe-9f68-4e3e0e7ed56f","executionInfo":{"status":"ok","timestamp":1586194924241,"user_tz":-330,"elapsed":758,"user":{"displayName":"Abhinav Havaldar","photoUrl":"","userId":"17469083248397030696"}},"colab":{"base_uri":"https://localhost:8080/","height":289}},"source":["model.load_state_dict(torch.load('/content/gdrive/My Drive/data/control-model-monodirectional-0.pt'))\n","model.eval()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Seq2Seq(\n","  (fc_in): Linear(in_features=512, out_features=512, bias=True)\n","  (fc_act): Tanh()\n","  (encoder): EncoderRNNEncDec(\n","    (embedding): Embedding(30004, 256)\n","    (rnn): GRU(256, 512)\n","    (fc_out): Linear(in_features=512, out_features=512, bias=True)\n","    (activation): Tanh()\n","  )\n","  (decoder): DecoderRNNEncDec(\n","    (embedding): Embedding(30004, 256)\n","    (rnn): GRU(768, 512)\n","    (max_out): Linear(in_features=1280, out_features=800, bias=True)\n","    (out): Linear(in_features=400, out_features=30004, bias=True)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":74}]},{"cell_type":"code","metadata":{"id":"Z0bsfjqM3v1Q","colab_type":"code","outputId":"a01b9355-6428-4d5d-e398-70a3a07dc085","executionInfo":{"status":"ok","timestamp":1586188745608,"user_tz":-330,"elapsed":11726517,"user":{"displayName":"Abhinav Havaldar","photoUrl":"","userId":"17469083248397030696"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["N_EPOCHS = 10\n","\n","for epoch in range(1, N_EPOCHS):\n","    train_iterator.init_epoch() # Processes like shuffling that happen before epoch.\n","    start_time = time.time()\n","    train_loss = train(model, train_iterator, optimizer, criterion) \n","    end_time = time.time()\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss: }')\n","\n","    # Checkpoint to ensure progrerss isn't lost.\n","    torch.save(model.state_dict(), f'/content/gdrive/My Drive/data/control-model-monodirectional-{epoch}.pt')\n","    model.load_state_dict(torch.load(f'/content/gdrive/My Drive/data/control-model-monodirectional-{epoch}.pt'))\n","    model.eval()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch: 02 | Time: 197m 1s\n","\tTrain Loss:  3.0190634663087166\n","Epoch: 03 | Time: 196m 30s\n","\tTrain Loss:  2.770725098545351\n","Epoch: 04 | Time: 195m 0s\n","\tTrain Loss:  2.6412053691687816\n","Epoch: 05 | Time: 194m 12s\n","\tTrain Loss:  2.556920369685852\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1BkVKtY_ldUE","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}