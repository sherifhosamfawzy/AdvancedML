{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"rework.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOy4hZRdXHz4h4g4UQbSPUv"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"nwL0wdUxgJX0","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torchtext.datasets import TranslationDataset, Multi30k\n","from torchtext.data import Field, BucketIterator\n","import spacy\n","import numpy as np\n","import random\n","import math\n","import time\n","from nltk.translate.bleu_score import sentence_bleu"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cqSPn-4zgMTt","colab_type":"code","colab":{}},"source":["SEED = 1234\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"d107U8IWgTeA","colab_type":"code","outputId":"4f2ef56a-c540-4c20-f783-6f43b1ab7f93","executionInfo":{"status":"ok","timestamp":1583408598040,"user_tz":0,"elapsed":6548,"user":{"displayName":"Abhinav Havaldar","photoUrl":"","userId":"17469083248397030696"}},"colab":{"base_uri":"https://localhost:8080/","height":275}},"source":["!python -m spacy download en\n","!python -m spacy download de\n","\n","spacy_en = spacy.load('en')\n","spacy_de = spacy.load('de')\n","\n","def tokenize_en(text):\n","    return [tok.text for tok in spacy_en.tokenizer(text)]\n","\n","def tokenize_de(text):\n","    return [tok.text for tok in spacy_de.tokenizer(text)]\n","\n","    \n","sourceLanguage = Field( tokenize = tokenize_en, \n","                        init_token = '<sos>', \n","                        eos_token = '<eos>')\n","\n","targetLanguage = Field( tokenize = tokenize_de, \n","                        init_token = '<sos>', \n","                        eos_token = '<eos>')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: en_core_web_sm==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz#egg=en_core_web_sm==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('en_core_web_sm')\n","\u001b[38;5;2m✔ Linking successful\u001b[0m\n","/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n","/usr/local/lib/python3.6/dist-packages/spacy/data/en\n","You can now load the model via spacy.load('en')\n","Requirement already satisfied: de_core_news_sm==2.1.0 from https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.1.0/de_core_news_sm-2.1.0.tar.gz#egg=de_core_news_sm==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('de_core_news_sm')\n","\u001b[38;5;2m✔ Linking successful\u001b[0m\n","/usr/local/lib/python3.6/dist-packages/de_core_news_sm -->\n","/usr/local/lib/python3.6/dist-packages/spacy/data/de\n","You can now load the model via spacy.load('de')\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OUoJpNzhgUoY","colab_type":"code","outputId":"c8689a5a-491f-4d4c-cd10-f7e9175fb1e2","executionInfo":{"status":"ok","timestamp":1583409262348,"user_tz":0,"elapsed":34253,"user":{"displayName":"Abhinav Havaldar","photoUrl":"","userId":"17469083248397030696"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["train_data, valid_data, test_data = Multi30k.splits(exts = ('.en', '.de'), fields = (sourceLanguage, targetLanguage))\n","sourceLanguage.build_vocab(train_data, min_freq = 2)\n","targetLanguage.build_vocab(train_data, min_freq = 2)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["downloading training.tar.gz\n"],"name":"stdout"},{"output_type":"stream","text":["training.tar.gz: 100%|██████████| 1.21M/1.21M [00:01<00:00, 687kB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["downloading validation.tar.gz\n"],"name":"stdout"},{"output_type":"stream","text":["validation.tar.gz: 100%|██████████| 46.3k/46.3k [00:00<00:00, 236kB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["downloading mmt_task1_test2016.tar.gz\n"],"name":"stdout"},{"output_type":"stream","text":["mmt_task1_test2016.tar.gz: 100%|██████████| 66.2k/66.2k [00:00<00:00, 226kB/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"-mRQNOpvg5Ab","colab_type":"code","colab":{}},"source":["BATCH_SIZE = 1\n","INPUT_DIM  = len(sourceLanguage.vocab) # Kx\n","OUTPUT_DIM = len(targetLanguage.vocab) # Ky\n","EMB_DIM = 256 # m \n","HID_DIM = 512 # n\n","MAXOUT_DIM = 400 # l \n","ATT_HID_DIM = 1000 # n'\n","\n","train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n","    (train_data, valid_data, test_data), \n","    batch_size = BATCH_SIZE,\n","    device = device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dvnFf-2Jh5H8","colab_type":"code","colab":{}},"source":["class EncoderRNN(nn.Module):\n","    def __init__(self, input_dim, embedding_dim, device):\n","        super(EncoderRNN, self).__ini__()\n","        self.embedding_dim  = embedding_dim\n","        self.embedding      = nn.Embedding(input_dim, embedding_dim)\n","        self.rnn            = nn.GRU(embedding_dim, embedding_dim)\n","\n","    def forward(self, input, hidden):\n","        output          = self.embedding(input).view(1, 1, -1)\n","        output, hidden  = self.rnn(emb, hidden)\n","        return output, hidden\n","\n","    def initHidden(self):\n","        return torch.zeros(1, 1, self.hidden_size, device=self.device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"d40jIl5rmHCx","colab_type":"code","colab":{}},"source":["class DecoderRNN(nn.Module):\n","    def __init__(self, hidden_dim, output_dim, device):\n","        super(DecoderRNN, self).__init__()\n","        self.embedding = nn.Embedding(output_dim, hidden_dim)\n","        self.rnn = nn.GRU(hidden_dim, hidden_dim)\n","        self.fully_connected = nn.Linear(hidden_dim, output_dim)\n","        self.softmax = nn.LogSoftmax(dim=1)\n","\n","    def forward(self, input, hidden):\n","        output = self.embedding(input)\n","        output = F.relu(output)\n","        output, hidden = nn.GRU(output, hidden)\n","        output = self.softmax(output)\n","        return output, hidden\n","\n","    def initHidden(self):\n","        return torch.zeros(1, 1, self.hidden_size, device=self.device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lio5XdG7qZGd","colab_type":"code","colab":{}},"source":["def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, \n","          decoder_optimizer, criterion, max_length=20):\n","    encoder_hidden = encoder.initHidden()\n","\n","    encoder_optimizer.zero_grad()\n","    decoder_optimizer.zero_grad()\n","\n","    input_length = input_tensor.size(0)\n","    target_length = target_tensor.size(0)\n","\n","    encoder_outputs = torch.zeros(max_length,\n","                                  encoder.hidden_size, \n","                                  device=device)\n","\n","    loss = 0\n","\n","    for ei in range(input_length):\n","        encoder_output, encoder_hidden = encoder(\n","            input_tensor[ei], encoder_hidden)\n","        encoder_outputs[ei] = encoder_output[0, 0]\n","\n","    decoder_input = torch.tensor([[SOS_token]], device=device)\n","    decoder_hidden = encoder_hidden\n","\n","    for di in range(target_length):\n","        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n","        topv, topi = decoder_output.topk(1)\n","        decoder_input = topi.squeeze().detach() \n","\n","        loss += criterion(decoder_output, target_tensor[di])\n","        if decoder_input.item() == EOS_token:\n","            break\n","\n","    loss.backward()\n","\n","    encoder_optimizer.step()\n","    decoder_optimizer.step()\n","\n","    return loss.item() / target_length"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mbf4ZiUFsKG3","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rv5wiziPvu8F","colab_type":"code","colab":{}},"source":["def beam_search(decoder, encoder_hidden, beam_width=3, target_lenght):\n","    hypotheses = [(1.0, [SOS_token], encoder_hidden)]\n","    for i in range(1, target_length):\n","        for hypothesis in hypotheses:\n","            score, seq, hidden = hypothesis\n","            decoder_output, decoder_hidden = decoder(seq[-1], hidden)\n","            prob, label = decoder_output.topk(beam_width)\n","            hypotheses += [(score*prob[i], seq + label, decoder_hidden) for i in range(beam_width)]\n","        hypotheses = sorted(hypotheses)[:5]\n","    _, seq, _ = max(hypotheses)\n","    return seq[1:-1]"],"execution_count":0,"outputs":[]}]}